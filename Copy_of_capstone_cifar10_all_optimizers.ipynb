{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemakumar5153/cnn-optimization/blob/main/Copy_of_capstone_cifar10_all_optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5hdE_JNr7WNV",
        "outputId": "8fd4507d-3aa6-4fda-db18-d201d374c704"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxXnWnGYVwJM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,Activation\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.datasets import cifar100\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7R8YRT4VwgV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from google.colab import files\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from google.colab import drive\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5v54ci67c0p"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "XyfPmJ_B7vUG",
        "outputId": "183d6b6b-808e-4685-82b5-18a4d8f17ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: [3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f864fa01f90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(\"Label: {}\".format(y_train[8000]))\n",
        "plt.imshow(X_train[8000], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKXsMRiM8BQS",
        "outputId": "7afc21a5-3529-48a8-9004-37c44865e4b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it's always better to normalize \n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n"
      ],
      "metadata": {
        "id": "ULHzlaHvleR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvnPuxX7leU5",
        "outputId": "88d3f3e5-fd42-4d1f-84fa-b253e258eaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it's always better to normalize \n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n"
      ],
      "metadata": {
        "id": "MJmQ4fLyosJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt-moqY6lecO",
        "outputId": "6e10d6c3-2f43-4f57-8e84-80bcf19ec6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Images in X_train:\", X_train.shape[0])\n",
        "print(\"Images in X_test:\", X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9H7E7yVlpUJ",
        "outputId": "9c0a785e-6982-433a-a607-331ff60aac4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "Images in X_train: 50000\n",
            "Images in X_test: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"One value of y_train:\", y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZByc1vqlpaA",
        "outputId": "b8092352-ceb4-4467-a644-f62cc07bee67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (50000, 10)\n",
            "One value of y_train: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ut9z5DZ1lpcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smW9gPRX_xFB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adadelta,Adagrad,Adam,RMSprop,SGD\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from tensorflow.keras.layers import Conv2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDr7f5p4azQw"
      },
      "source": [
        "## CUSTOM MODEL 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ielW9Oe4_NRL"
      },
      "outputs": [],
      "source": [
        "def build_model(optimizer):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(32,32,3)))\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "  model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['SGD','Adagrad','Adadelta', 'RMSprop', 'Adam']\n",
        "\n",
        "for i in optimizers:\n",
        "\n",
        "  print('\\n=================== Running with {0} Optimizer ====================\\n'.format(i))\n",
        "  model = build_model(i)\n",
        "  hist=model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split = 0.3)\n",
        "  m1=model.evaluate(X_test, y_test)\n",
        "\n",
        "  print('\\n Model test accuracy with {0} optimizer is {1:.2%} \\n'.format(i,m1[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmOVZDk22JlK",
        "outputId": "f23e4f9a-fbc0-4088-ec89-1de341f74084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================== Running with SGD Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 17s 6ms/step - loss: 1.8446 - accuracy: 0.3402 - val_loss: 1.7102 - val_accuracy: 0.3851\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.5321 - accuracy: 0.4567 - val_loss: 1.5768 - val_accuracy: 0.4384\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.3615 - accuracy: 0.5168 - val_loss: 1.3552 - val_accuracy: 0.5177\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.2442 - accuracy: 0.5572 - val_loss: 1.2774 - val_accuracy: 0.5406\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.1495 - accuracy: 0.5914 - val_loss: 1.2779 - val_accuracy: 0.5487\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.0646 - accuracy: 0.6253 - val_loss: 1.2029 - val_accuracy: 0.5808\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.9828 - accuracy: 0.6552 - val_loss: 1.2253 - val_accuracy: 0.5763\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.9007 - accuracy: 0.6847 - val_loss: 1.2019 - val_accuracy: 0.5835\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.8131 - accuracy: 0.7158 - val_loss: 1.2088 - val_accuracy: 0.5894\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.7232 - accuracy: 0.7486 - val_loss: 1.2487 - val_accuracy: 0.5917\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2430 - accuracy: 0.5871\n",
            "\n",
            " Model test accuracy with SGD optimizer is 58.71% \n",
            "\n",
            "\n",
            "=================== Running with Adagrad Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 2.0206 - accuracy: 0.2797 - val_loss: 1.8786 - val_accuracy: 0.3377\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.8153 - accuracy: 0.3633 - val_loss: 1.7821 - val_accuracy: 0.3783\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.7263 - accuracy: 0.4006 - val_loss: 1.7190 - val_accuracy: 0.3951\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.6649 - accuracy: 0.4220 - val_loss: 1.6705 - val_accuracy: 0.4157\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.6199 - accuracy: 0.4374 - val_loss: 1.6305 - val_accuracy: 0.4332\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.5815 - accuracy: 0.4493 - val_loss: 1.5977 - val_accuracy: 0.4428\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.5465 - accuracy: 0.4600 - val_loss: 1.5706 - val_accuracy: 0.4528\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.5163 - accuracy: 0.4709 - val_loss: 1.5484 - val_accuracy: 0.4586\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.4886 - accuracy: 0.4810 - val_loss: 1.5244 - val_accuracy: 0.4662\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.4639 - accuracy: 0.4889 - val_loss: 1.5038 - val_accuracy: 0.4758\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4830 - accuracy: 0.4781\n",
            "\n",
            " Model test accuracy with Adagrad optimizer is 47.81% \n",
            "\n",
            "\n",
            "=================== Running with Adadelta Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 2.2626 - accuracy: 0.1959 - val_loss: 2.2218 - val_accuracy: 0.2454\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 2.1817 - accuracy: 0.2502 - val_loss: 2.1458 - val_accuracy: 0.2731\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 2.1116 - accuracy: 0.2793 - val_loss: 2.0835 - val_accuracy: 0.2842\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 2.0540 - accuracy: 0.2999 - val_loss: 2.0333 - val_accuracy: 0.3074\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 2.0080 - accuracy: 0.3170 - val_loss: 1.9948 - val_accuracy: 0.3187\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.9723 - accuracy: 0.3295 - val_loss: 1.9636 - val_accuracy: 0.3251\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.9432 - accuracy: 0.3359 - val_loss: 1.9402 - val_accuracy: 0.3363\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.9195 - accuracy: 0.3436 - val_loss: 1.9180 - val_accuracy: 0.3407\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.8992 - accuracy: 0.3479 - val_loss: 1.9014 - val_accuracy: 0.3477\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 1.8813 - accuracy: 0.3572 - val_loss: 1.8845 - val_accuracy: 0.3538\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.8751 - accuracy: 0.3575\n",
            "\n",
            " Model test accuracy with Adadelta optimizer is 35.75% \n",
            "\n",
            "\n",
            "=================== Running with RMSprop Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.5305 - accuracy: 0.4590 - val_loss: 1.1836 - val_accuracy: 0.5849\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 1.0656 - accuracy: 0.6300 - val_loss: 1.1238 - val_accuracy: 0.6106\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.8266 - accuracy: 0.7147 - val_loss: 1.0694 - val_accuracy: 0.6384\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.6243 - accuracy: 0.7866 - val_loss: 1.2034 - val_accuracy: 0.6294\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.4410 - accuracy: 0.8524 - val_loss: 1.2998 - val_accuracy: 0.6355\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.2935 - accuracy: 0.9017 - val_loss: 1.7127 - val_accuracy: 0.6039\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1911 - accuracy: 0.9371 - val_loss: 1.9683 - val_accuracy: 0.6119\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1276 - accuracy: 0.9567 - val_loss: 2.4565 - val_accuracy: 0.6189\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0979 - accuracy: 0.9679 - val_loss: 2.8592 - val_accuracy: 0.6015\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0788 - accuracy: 0.9758 - val_loss: 3.2541 - val_accuracy: 0.6167\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.2681 - accuracy: 0.6153\n",
            "\n",
            " Model test accuracy with RMSprop optimizer is 61.53% \n",
            "\n",
            "\n",
            "=================== Running with Adam Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 7s 6ms/step - loss: 1.5232 - accuracy: 0.4512 - val_loss: 1.4090 - val_accuracy: 0.4964\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 1.1561 - accuracy: 0.5909 - val_loss: 1.1560 - val_accuracy: 0.5870\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.9414 - accuracy: 0.6702 - val_loss: 1.1533 - val_accuracy: 0.6030\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.7521 - accuracy: 0.7359 - val_loss: 1.1768 - val_accuracy: 0.6093\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.5719 - accuracy: 0.7993 - val_loss: 1.2422 - val_accuracy: 0.6151\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4005 - accuracy: 0.8605 - val_loss: 1.4179 - val_accuracy: 0.6077\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.2767 - accuracy: 0.9047 - val_loss: 1.6876 - val_accuracy: 0.5989\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.1903 - accuracy: 0.9351 - val_loss: 2.0215 - val_accuracy: 0.5998\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.1377 - accuracy: 0.9529 - val_loss: 2.3768 - val_accuracy: 0.5875\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.1096 - accuracy: 0.9638 - val_loss: 2.5807 - val_accuracy: 0.5947\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6055 - accuracy: 0.5873\n",
            "\n",
            " Model test accuracy with Adam optimizer is 58.73% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kerv6fCRajlu"
      },
      "source": [
        "## CUSTOM MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vim4H5pRNcwa"
      },
      "outputs": [],
      "source": [
        "def build_model1(optimizer):\n",
        "  model=Sequential()\n",
        "  model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(32, 32, 3)))\n",
        "  model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.MaxPool2D())\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.MaxPool2D())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Conv2D(128,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.MaxPool2D())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512,activation='relu'))\n",
        "  model.add(layers.Dense(10,activation='softmax'))\n",
        "  model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['SGD','Adagrad','Adadelta', 'RMSprop', 'Adam']\n",
        "\n",
        "for i in optimizers:\n",
        "\n",
        "  print('\\n=================== Running with {0} Optimizer ====================\\n'.format(i))\n",
        "  model = build_model1(i)\n",
        "  hist=model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split = 0.3)\n",
        "  m1=model.evaluate(X_test, y_test)\n",
        "\n",
        "  print('\\n Model test accuracy with {0} optimizer is {1:.2%} \\n'.format(i,m1[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_Cup07mCBfn",
        "outputId": "8fa8348a-83a6-419e-a9cd-36d0efa35832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================== Running with SGD Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 9s 7ms/step - loss: 2.1959 - accuracy: 0.1759 - val_loss: 2.0387 - val_accuracy: 0.2723\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 8s 8ms/step - loss: 1.9668 - accuracy: 0.2809 - val_loss: 1.8846 - val_accuracy: 0.3367\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 8s 8ms/step - loss: 1.7719 - accuracy: 0.3504 - val_loss: 1.7427 - val_accuracy: 0.3747\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.6645 - accuracy: 0.3913 - val_loss: 1.6294 - val_accuracy: 0.4210\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.5847 - accuracy: 0.4175 - val_loss: 1.5610 - val_accuracy: 0.4406\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.5285 - accuracy: 0.4419 - val_loss: 1.5126 - val_accuracy: 0.4538\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.4697 - accuracy: 0.4643 - val_loss: 1.4273 - val_accuracy: 0.5003\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.4242 - accuracy: 0.4814 - val_loss: 1.3921 - val_accuracy: 0.5069\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 8s 8ms/step - loss: 1.3785 - accuracy: 0.4951 - val_loss: 1.3612 - val_accuracy: 0.5132\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.3405 - accuracy: 0.5103 - val_loss: 1.2881 - val_accuracy: 0.5548\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2782 - accuracy: 0.5599\n",
            "\n",
            " Model test accuracy with SGD optimizer is 55.99% \n",
            "\n",
            "\n",
            "=================== Running with Adagrad Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2954 - accuracy: 0.1115 - val_loss: 2.2813 - val_accuracy: 0.1981\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2143 - accuracy: 0.1753 - val_loss: 2.1293 - val_accuracy: 0.2259\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.0604 - accuracy: 0.2367 - val_loss: 2.0350 - val_accuracy: 0.2549\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 2.0137 - accuracy: 0.2581 - val_loss: 2.0098 - val_accuracy: 0.2729\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.9872 - accuracy: 0.2715 - val_loss: 1.9848 - val_accuracy: 0.2915\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.9615 - accuracy: 0.2820 - val_loss: 1.9559 - val_accuracy: 0.3105\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.9339 - accuracy: 0.2949 - val_loss: 1.9313 - val_accuracy: 0.3236\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.8998 - accuracy: 0.3139 - val_loss: 1.8969 - val_accuracy: 0.3357\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.8671 - accuracy: 0.3291 - val_loss: 1.8610 - val_accuracy: 0.3498\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.8331 - accuracy: 0.3392 - val_loss: 1.8422 - val_accuracy: 0.3445\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.8269 - accuracy: 0.3565\n",
            "\n",
            " Model test accuracy with Adagrad optimizer is 35.65% \n",
            "\n",
            "\n",
            "=================== Running with Adadelta Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 10s 9ms/step - loss: 2.3140 - accuracy: 0.1065 - val_loss: 2.2988 - val_accuracy: 0.1673\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 2.3030 - accuracy: 0.1095 - val_loss: 2.2959 - val_accuracy: 0.1637\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2979 - accuracy: 0.1145 - val_loss: 2.2932 - val_accuracy: 0.1704\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2918 - accuracy: 0.1242 - val_loss: 2.2900 - val_accuracy: 0.1735\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 2.2878 - accuracy: 0.1288 - val_loss: 2.2861 - val_accuracy: 0.1771\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 2.2788 - accuracy: 0.1356 - val_loss: 2.2811 - val_accuracy: 0.1861\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 2.2724 - accuracy: 0.1448 - val_loss: 2.2745 - val_accuracy: 0.1985\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2618 - accuracy: 0.1503 - val_loss: 2.2661 - val_accuracy: 0.2009\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2524 - accuracy: 0.1605 - val_loss: 2.2554 - val_accuracy: 0.2094\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 2.2354 - accuracy: 0.1737 - val_loss: 2.2412 - val_accuracy: 0.2153\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2405 - accuracy: 0.2146\n",
            "\n",
            " Model test accuracy with Adadelta optimizer is 21.46% \n",
            "\n",
            "\n",
            "=================== Running with RMSprop Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 10s 9ms/step - loss: 1.6758 - accuracy: 0.3892 - val_loss: 1.3544 - val_accuracy: 0.5294\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.3004 - accuracy: 0.5352 - val_loss: 1.1462 - val_accuracy: 0.6191\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.1709 - accuracy: 0.5842 - val_loss: 1.0714 - val_accuracy: 0.6508\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.1068 - accuracy: 0.6098 - val_loss: 1.0839 - val_accuracy: 0.6792\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.0637 - accuracy: 0.6253 - val_loss: 1.1430 - val_accuracy: 0.6863\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.0467 - accuracy: 0.6405 - val_loss: 1.0099 - val_accuracy: 0.7075\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.0231 - accuracy: 0.6491 - val_loss: 1.0545 - val_accuracy: 0.6661\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.0288 - accuracy: 0.6527 - val_loss: 1.0707 - val_accuracy: 0.6588\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.0213 - accuracy: 0.6525 - val_loss: 1.0068 - val_accuracy: 0.6777\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 8s 7ms/step - loss: 1.0222 - accuracy: 0.6538 - val_loss: 1.0851 - val_accuracy: 0.6429\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0904 - accuracy: 0.6422\n",
            "\n",
            " Model test accuracy with RMSprop optimizer is 64.22% \n",
            "\n",
            "\n",
            "=================== Running with Adam Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 1.6339 - accuracy: 0.3960 - val_loss: 1.2762 - val_accuracy: 0.5489\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.2408 - accuracy: 0.5529 - val_loss: 1.0532 - val_accuracy: 0.6307\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.0964 - accuracy: 0.6047 - val_loss: 1.0290 - val_accuracy: 0.6511\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 1.0006 - accuracy: 0.6429 - val_loss: 0.8652 - val_accuracy: 0.7034\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 0.9324 - accuracy: 0.6682 - val_loss: 0.7975 - val_accuracy: 0.7309\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 0.8811 - accuracy: 0.6911 - val_loss: 0.8003 - val_accuracy: 0.7255\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 9s 8ms/step - loss: 0.8456 - accuracy: 0.6990 - val_loss: 0.7762 - val_accuracy: 0.7342\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 0.8061 - accuracy: 0.7166 - val_loss: 0.7240 - val_accuracy: 0.7539\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 0.7851 - accuracy: 0.7221 - val_loss: 0.7072 - val_accuracy: 0.7545\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 7s 7ms/step - loss: 0.7578 - accuracy: 0.7325 - val_loss: 0.6972 - val_accuracy: 0.7564\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7174 - accuracy: 0.7493\n",
            "\n",
            " Model test accuracy with Adam optimizer is 74.93% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cypgeLCUad2A"
      },
      "source": [
        "## VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHWzsdP0h-kz",
        "outputId": "baeb0df2-3c9a-479b-f63c-7adfee281b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "vgg19 = VGG19(include_top=False,input_shape=(32,32,3))\n",
        "print(vgg19.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC5pWcdxlv82"
      },
      "outputs": [],
      "source": [
        "def ModelVGG19(optimizer):\n",
        "  modelvgg19=Sequential()\n",
        "  for layer in vgg19.layers:\n",
        "    modelvgg19.add(layer)\n",
        "\n",
        "  for layer in modelvgg19.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "  modelvgg19.add(Flatten())\n",
        "  modelvgg19.add(Dense(128))\n",
        "  modelvgg19.add(Dense(10,activation='softmax'))\n",
        "  modelvgg19.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "  return modelvgg19\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['SGD','Adagrad','Adadelta', 'RMSprop', 'Adam']\n",
        "\n",
        "for i in optimizers:\n",
        "\n",
        "  print('\\n=================== Running with {0} Optimizer ====================\\n'.format(i))\n",
        "  modelvgg19 = ModelVGG19(i)\n",
        "  hist=modelvgg19.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1, validation_split = 0.3)\n",
        "  m1=modelvgg19.evaluate(X_test, y_test)\n",
        "\n",
        "  print('\\n Model test accuracy with {0} optimizer is {1:.2%} \\n'.format(i,m1[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeX_Jx_ur3XY",
        "outputId": "239e4a16-eb33-485b-f687-b78d4b7830bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================== Running with SGD Optimizer ====================\n",
            "\n",
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 21s 18ms/step - loss: 1.7107 - accuracy: 0.4011 - val_loss: 1.5309 - val_accuracy: 0.4667\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.4726 - accuracy: 0.4868 - val_loss: 1.4833 - val_accuracy: 0.4744\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.4086 - accuracy: 0.5079 - val_loss: 1.3995 - val_accuracy: 0.5080\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 1.3685 - accuracy: 0.5211 - val_loss: 1.3545 - val_accuracy: 0.5255\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 23s 21ms/step - loss: 1.3413 - accuracy: 0.5331 - val_loss: 1.3424 - val_accuracy: 0.5296\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.3466 - accuracy: 0.5301\n",
            "\n",
            " Model test accuracy with SGD optimizer is 53.01% \n",
            "\n",
            "\n",
            "=================== Running with Adagrad Optimizer ====================\n",
            "\n",
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.9660 - accuracy: 0.3129 - val_loss: 1.7980 - val_accuracy: 0.3844\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 23s 21ms/step - loss: 1.7295 - accuracy: 0.4104 - val_loss: 1.6833 - val_accuracy: 0.4223\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 1.6464 - accuracy: 0.4366 - val_loss: 1.6249 - val_accuracy: 0.4433\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 1.5976 - accuracy: 0.4521 - val_loss: 1.5867 - val_accuracy: 0.4539\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 1.5640 - accuracy: 0.4635 - val_loss: 1.5593 - val_accuracy: 0.4637\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.5599 - accuracy: 0.4638\n",
            "\n",
            " Model test accuracy with Adagrad optimizer is 46.38% \n",
            "\n",
            "\n",
            "=================== Running with Adadelta Optimizer ====================\n",
            "\n",
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 25s 22ms/step - loss: 2.5188 - accuracy: 0.1253 - val_loss: 2.4054 - val_accuracy: 0.1331\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 2.3410 - accuracy: 0.1510 - val_loss: 2.2934 - val_accuracy: 0.1533\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 24s 22ms/step - loss: 2.2567 - accuracy: 0.1716 - val_loss: 2.2311 - val_accuracy: 0.1766\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 2.2044 - accuracy: 0.1908 - val_loss: 2.1874 - val_accuracy: 0.1935\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 2.1645 - accuracy: 0.2105 - val_loss: 2.1510 - val_accuracy: 0.2169\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 2.1526 - accuracy: 0.2204\n",
            "\n",
            " Model test accuracy with Adadelta optimizer is 22.04% \n",
            "\n",
            "\n",
            "=================== Running with RMSprop Optimizer ====================\n",
            "\n",
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 20s 17ms/step - loss: 1.4591 - accuracy: 0.4876 - val_loss: 1.4231 - val_accuracy: 0.5057\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2981 - accuracy: 0.5478 - val_loss: 1.2750 - val_accuracy: 0.5543\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2580 - accuracy: 0.5615 - val_loss: 1.2708 - val_accuracy: 0.5581\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2344 - accuracy: 0.5671 - val_loss: 1.2584 - val_accuracy: 0.5587\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2246 - accuracy: 0.5743 - val_loss: 1.2778 - val_accuracy: 0.5549\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.2856 - accuracy: 0.5548\n",
            "\n",
            " Model test accuracy with RMSprop optimizer is 55.48% \n",
            "\n",
            "\n",
            "=================== Running with Adam Optimizer ====================\n",
            "\n",
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 20s 17ms/step - loss: 1.4446 - accuracy: 0.4937 - val_loss: 1.3052 - val_accuracy: 0.5429\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 24s 22ms/step - loss: 1.2828 - accuracy: 0.5519 - val_loss: 1.3052 - val_accuracy: 0.5477\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 1.2420 - accuracy: 0.5672 - val_loss: 1.2599 - val_accuracy: 0.5578\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2229 - accuracy: 0.5731 - val_loss: 1.2628 - val_accuracy: 0.5568\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 1.2097 - accuracy: 0.5793 - val_loss: 1.2652 - val_accuracy: 0.5569\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.2704 - accuracy: 0.5612\n",
            "\n",
            " Model test accuracy with Adam optimizer is 56.12% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dci6poUuaOCe"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq0DZ4HZCiOA",
        "outputId": "dd8ff879-4242-43d6-b4ee-61ef27be2905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16(include_top=False,input_shape=(32,32,3))\n",
        "print(vgg16.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZTY7UxRCiZd"
      },
      "outputs": [],
      "source": [
        "def ModelVGG16(optimizer):\n",
        "  modelvgg16=Sequential()\n",
        "  for layer in vgg16.layers:\n",
        "    modelvgg16.add(layer)\n",
        "\n",
        "  for layer in modelvgg16.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "  modelvgg16.add(Flatten())\n",
        "  modelvgg16.add(Dense(128))\n",
        "  modelvgg16.add(Dense(10,activation='softmax'))\n",
        "  modelvgg16.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "  return modelvgg16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['SGD','Adagrad','Adadelta', 'RMSprop', 'Adam']\n",
        "\n",
        "for i in optimizers:\n",
        "\n",
        "  print('\\n=================== Running with {0} Optimizer ====================\\n'.format(i))\n",
        "  modelvgg16 = ModelVGG16(i)\n",
        "  hist=modelvgg16.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split = 0.3)\n",
        "  m1=modelvgg16.evaluate(X_test, y_test)\n",
        "\n",
        "  print('\\n Model test accuracy with {0} optimizer is {1:.2%} \\n'.format(i,m1[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL9hGu9ZtWVr",
        "outputId": "0075251d-b6c1-4f05-8f9b-c0298563288a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================== Running with SGD Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 1.7286 - accuracy: 0.3991 - val_loss: 1.5286 - val_accuracy: 0.4727\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.4523 - accuracy: 0.4963 - val_loss: 1.4132 - val_accuracy: 0.5107\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.3760 - accuracy: 0.5208 - val_loss: 1.3573 - val_accuracy: 0.5267\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.3346 - accuracy: 0.5380 - val_loss: 1.3514 - val_accuracy: 0.5269\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.3019 - accuracy: 0.5465 - val_loss: 1.3148 - val_accuracy: 0.5389\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.2801 - accuracy: 0.5564 - val_loss: 1.2905 - val_accuracy: 0.5492\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.2631 - accuracy: 0.5607 - val_loss: 1.2947 - val_accuracy: 0.5531\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.2490 - accuracy: 0.5665 - val_loss: 1.2630 - val_accuracy: 0.5613\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.2367 - accuracy: 0.5692 - val_loss: 1.2713 - val_accuracy: 0.5517\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.2263 - accuracy: 0.5752 - val_loss: 1.2549 - val_accuracy: 0.5658\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2706 - accuracy: 0.5536\n",
            "\n",
            " Model test accuracy with SGD optimizer is 55.36% \n",
            "\n",
            "\n",
            "=================== Running with Adagrad Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 2.0290 - accuracy: 0.2851 - val_loss: 1.8354 - val_accuracy: 0.3816\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.7600 - accuracy: 0.4068 - val_loss: 1.7009 - val_accuracy: 0.4291\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.6632 - accuracy: 0.4399 - val_loss: 1.6322 - val_accuracy: 0.4485\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.6063 - accuracy: 0.4567 - val_loss: 1.5877 - val_accuracy: 0.4627\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.5675 - accuracy: 0.4689 - val_loss: 1.5557 - val_accuracy: 0.4717\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.5381 - accuracy: 0.4783 - val_loss: 1.5304 - val_accuracy: 0.4813\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.5149 - accuracy: 0.4853 - val_loss: 1.5107 - val_accuracy: 0.4871\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.4958 - accuracy: 0.4907 - val_loss: 1.4935 - val_accuracy: 0.4925\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.4797 - accuracy: 0.4955 - val_loss: 1.4792 - val_accuracy: 0.4965\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.4656 - accuracy: 0.4995 - val_loss: 1.4667 - val_accuracy: 0.5003\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.4768 - accuracy: 0.4931\n",
            "\n",
            " Model test accuracy with Adagrad optimizer is 49.31% \n",
            "\n",
            "\n",
            "=================== Running with Adadelta Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 2.4558 - accuracy: 0.1007 - val_loss: 2.3750 - val_accuracy: 0.1153\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 2.3344 - accuracy: 0.1306 - val_loss: 2.2894 - val_accuracy: 0.1478\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 2.2648 - accuracy: 0.1613 - val_loss: 2.2339 - val_accuracy: 0.1733\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 2.2161 - accuracy: 0.1857 - val_loss: 2.1919 - val_accuracy: 0.1964\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 2.1773 - accuracy: 0.2059 - val_loss: 2.1568 - val_accuracy: 0.2164\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 2.1439 - accuracy: 0.2259 - val_loss: 2.1254 - val_accuracy: 0.2341\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 2.1135 - accuracy: 0.2437 - val_loss: 2.0965 - val_accuracy: 0.2517\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 2.0854 - accuracy: 0.2597 - val_loss: 2.0696 - val_accuracy: 0.2678\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 2.0594 - accuracy: 0.2765 - val_loss: 2.0447 - val_accuracy: 0.2831\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 2.0351 - accuracy: 0.2911 - val_loss: 2.0213 - val_accuracy: 0.2955\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.0241 - accuracy: 0.2920\n",
            "\n",
            " Model test accuracy with Adadelta optimizer is 29.20% \n",
            "\n",
            "\n",
            "=================== Running with RMSprop Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 1.4155 - accuracy: 0.5065 - val_loss: 1.2839 - val_accuracy: 0.5496\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.2465 - accuracy: 0.5648 - val_loss: 1.2406 - val_accuracy: 0.5709\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.2090 - accuracy: 0.5797 - val_loss: 1.2465 - val_accuracy: 0.5688\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.1892 - accuracy: 0.5864 - val_loss: 1.2122 - val_accuracy: 0.5816\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1765 - accuracy: 0.5919 - val_loss: 1.2284 - val_accuracy: 0.5721\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.1673 - accuracy: 0.5954 - val_loss: 1.2436 - val_accuracy: 0.5712\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1603 - accuracy: 0.5968 - val_loss: 1.2454 - val_accuracy: 0.5685\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1565 - accuracy: 0.6005 - val_loss: 1.2172 - val_accuracy: 0.5793\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.1518 - accuracy: 0.6013 - val_loss: 1.2199 - val_accuracy: 0.5824\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 1.1492 - accuracy: 0.6019 - val_loss: 1.2300 - val_accuracy: 0.5780\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2369 - accuracy: 0.5757\n",
            "\n",
            " Model test accuracy with RMSprop optimizer is 57.57% \n",
            "\n",
            "\n",
            "=================== Running with Adam Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 1.3974 - accuracy: 0.5107 - val_loss: 1.2837 - val_accuracy: 0.5539\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.2308 - accuracy: 0.5717 - val_loss: 1.2222 - val_accuracy: 0.5745\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1934 - accuracy: 0.5854 - val_loss: 1.2781 - val_accuracy: 0.5527\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1787 - accuracy: 0.5905 - val_loss: 1.2263 - val_accuracy: 0.5791\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1623 - accuracy: 0.5952 - val_loss: 1.2300 - val_accuracy: 0.5700\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1564 - accuracy: 0.5989 - val_loss: 1.2289 - val_accuracy: 0.5749\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1494 - accuracy: 0.6020 - val_loss: 1.2235 - val_accuracy: 0.5807\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1441 - accuracy: 0.6003 - val_loss: 1.2163 - val_accuracy: 0.5815\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 1.1406 - accuracy: 0.6043 - val_loss: 1.2284 - val_accuracy: 0.5771\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 15s 14ms/step - loss: 1.1377 - accuracy: 0.6068 - val_loss: 1.2191 - val_accuracy: 0.5765\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2257 - accuracy: 0.5724\n",
            "\n",
            " Model test accuracy with Adam optimizer is 57.24% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz11oS1AbH36"
      },
      "source": [
        "## EFFICENT NET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efnb0 = tf.keras.applications.efficientnet.EfficientNetB0(weights='imagenet',include_top=False,input_shape=(32,32,3), classes=10)\n",
        "print(efnb0.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b6TvwRISrJo",
        "outputId": "9cd62bbc-8835-428b-e89c-d69fc0d0974e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"efficientnetb0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 32, 32, 3)    7           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 33, 33, 3)    0           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 16, 16, 32)   864         ['stem_conv_pad[0][0]']          \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 16, 16, 32)   128         ['stem_conv[0][0]']              \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 16, 16, 32)   0           ['stem_bn[0][0]']                \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 16, 16, 32)  288         ['stem_activation[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 16, 16, 32)  128         ['block1a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 16, 16, 32)  0           ['block1a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 16, 16, 32)   0           ['block1a_activation[0][0]',     \n",
            "                                                                  'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 16, 16, 16)   512         ['block1a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 16, 16, 16)  64          ['block1a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 16, 16, 96)   1536        ['block1a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 16, 16, 96)  384         ['block2a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 16, 16, 96)  0           ['block2a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 17, 17, 96)  0           ['block2a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 8, 8, 96)    864         ['block2a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 8, 8, 96)    384         ['block2a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 8, 8, 96)    0           ['block2a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 8, 8, 96)     0           ['block2a_activation[0][0]',     \n",
            "                                                                  'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 8, 8, 24)     2304        ['block2a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 8, 8, 24)    96          ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 8, 8, 144)    3456        ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 8, 8, 144)   576         ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 8, 8, 144)   0           ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 8, 8, 144)   1296        ['block2b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 8, 8, 144)   576         ['block2b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 8, 8, 144)   0           ['block2b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 8, 8, 144)    0           ['block2b_activation[0][0]',     \n",
            "                                                                  'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 8, 8, 24)     3456        ['block2b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 8, 8, 24)    96          ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 8, 8, 24)     0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 8, 8, 24)     0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 8, 8, 144)    3456        ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 8, 8, 144)   576         ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 8, 8, 144)   0           ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 11, 11, 144)  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 4, 4, 144)   3600        ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 4, 4, 144)   576         ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 4, 4, 144)   0           ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 4, 4, 144)    0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 4, 4, 40)     5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 4, 4, 40)    160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 4, 4, 240)    9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 4, 4, 240)   960         ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 4, 4, 240)   0           ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 4, 4, 240)   6000        ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 4, 4, 240)   960         ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 4, 4, 240)   0           ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 4, 4, 240)    0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 4, 4, 40)     9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 4, 4, 40)    160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 4, 4, 40)     0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 4, 4, 40)     0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 4, 4, 240)    9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 4, 4, 240)   960         ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 4, 4, 240)   0           ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 5, 5, 240)   0           ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 2, 2, 240)   2160        ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 2, 2, 240)   960         ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 2, 2, 240)   0           ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 2, 2, 240)    0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 2, 2, 80)     19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 2, 2, 80)    320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 2, 2, 480)    38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 2, 2, 480)   1920        ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 2, 2, 480)   0           ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 2, 2, 480)   4320        ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 2, 2, 480)   1920        ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 2, 2, 480)   0           ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 2, 2, 480)    0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 2, 2, 80)     38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 2, 2, 80)    320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 2, 2, 80)     0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 2, 2, 80)     0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 2, 2, 480)    38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 2, 2, 480)   1920        ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 2, 2, 480)   0           ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 2, 2, 480)   4320        ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 2, 2, 480)   1920        ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 2, 2, 480)   0           ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 2, 2, 480)    0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 2, 2, 80)     38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 2, 2, 80)    320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 2, 2, 80)     0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 2, 2, 80)     0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 2, 2, 480)    38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 2, 2, 480)   1920        ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 2, 2, 480)   0           ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 2, 2, 480)   12000       ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 2, 2, 480)   1920        ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 2, 2, 480)   0           ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 2, 2, 480)    0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 2, 2, 112)    53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 2, 2, 672)   0           ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 2, 2, 672)   16800       ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 2, 2, 672)   0           ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 2, 2, 112)    0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 2, 2, 112)    0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 2, 2, 672)   0           ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 2, 2, 672)   16800       ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 2, 2, 672)   0           ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 2, 2, 112)    0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 2, 2, 112)    0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 2, 2, 672)   0           ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 5, 5, 672)   0           ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 1, 1, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 1, 1, 672)   2688        ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 1, 1, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 1, 1, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 1, 1, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 1, 1, 1152)  28800       ['block6b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 1, 1, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 1, 1, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 1, 1, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 1, 1, 1152)  28800       ['block6c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 1, 1, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 1, 1, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 1, 1, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 1, 1, 1152)  28800       ['block6d_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 1, 1, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 1, 1, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 1, 1, 192)    0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 1, 1, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 1, 1, 1152)  10368       ['block7a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 1, 1, 1152)  0           ['block7a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block7a_activation[0][0]',     \n",
            "                                                                  'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 1, 1, 320)    368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 1, 1, 320)   1280        ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 1, 1, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 1, 1, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 1, 1, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,023\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelEFN(optimizer):\n",
        "  modelefn=Sequential()\n",
        "    \n",
        "  modelefn.add(efnb0)\n",
        "  modelefn.add(GlobalAveragePooling2D())\n",
        "  modelefn.add(Dropout(0.5))\n",
        "  modelefn.add(Dense(10, activation='softmax'))\n",
        "  modelefn.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "  return modelefn"
      ],
      "metadata": {
        "id": "Fz-WS4RFRreV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['SGD','Adagrad','Adadelta', 'RMSprop', 'Adam']\n",
        "\n",
        "for i in optimizers:\n",
        "\n",
        "  print('\\n=================== Running with {0} Optimizer ====================\\n'.format(i))\n",
        "  modelefn = ModelEFN(i)\n",
        "  hist=modelefn.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split = 0.3)\n",
        "  m1=modelefn.evaluate(X_test, y_test)\n",
        "\n",
        "  print('\\n Model test accuracy with {0} optimizer is {1:.2%} \\n'.format(i,m1[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5OAi-kuSXiz",
        "outputId": "ce4e025b-7606-4af4-8336-276b6dc6db9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================== Running with SGD Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 56s 44ms/step - loss: 2.3680 - accuracy: 0.1880 - val_loss: 88.7678 - val_accuracy: 0.1041\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 45s 41ms/step - loss: 1.8987 - accuracy: 0.3042 - val_loss: 5.1495 - val_accuracy: 0.1050\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.7426 - accuracy: 0.3640 - val_loss: 2.4001 - val_accuracy: 0.1023\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.6619 - accuracy: 0.3969 - val_loss: 2.4559 - val_accuracy: 0.0880\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.5527 - accuracy: 0.4393 - val_loss: 2.3456 - val_accuracy: 0.1486\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.4706 - accuracy: 0.4687 - val_loss: 2.9328 - val_accuracy: 0.1128\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 45s 41ms/step - loss: 1.3969 - accuracy: 0.4982 - val_loss: 2.4166 - val_accuracy: 0.0815\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.3378 - accuracy: 0.5225 - val_loss: 2.3554 - val_accuracy: 0.1394\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 46s 42ms/step - loss: 1.2900 - accuracy: 0.5370 - val_loss: 2.7978 - val_accuracy: 0.0943\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 45s 42ms/step - loss: 1.3244 - accuracy: 0.5276 - val_loss: 3.5994 - val_accuracy: 0.1422\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 3.6016 - accuracy: 0.1420\n",
            "\n",
            " Model test accuracy with SGD optimizer is 14.20% \n",
            "\n",
            "\n",
            "=================== Running with Adagrad Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 56s 44ms/step - loss: 1.5632 - accuracy: 0.4615 - val_loss: 1.5527 - val_accuracy: 0.4588\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 1.3386 - accuracy: 0.5348 - val_loss: 1.2436 - val_accuracy: 0.5720\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.2857 - accuracy: 0.5551 - val_loss: 1.3699 - val_accuracy: 0.5279\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.2582 - accuracy: 0.5613 - val_loss: 1.1628 - val_accuracy: 0.5951\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.2383 - accuracy: 0.5716 - val_loss: 1.2748 - val_accuracy: 0.5461\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.2216 - accuracy: 0.5742 - val_loss: 1.1314 - val_accuracy: 0.6031\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.2054 - accuracy: 0.5779 - val_loss: 1.1198 - val_accuracy: 0.6096\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.1972 - accuracy: 0.5810 - val_loss: 1.1237 - val_accuracy: 0.6079\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 1.1801 - accuracy: 0.5884 - val_loss: 1.1506 - val_accuracy: 0.6005\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 1.1636 - accuracy: 0.5930 - val_loss: 1.0885 - val_accuracy: 0.6210\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.0957 - accuracy: 0.6142\n",
            "\n",
            " Model test accuracy with Adagrad optimizer is 61.42% \n",
            "\n",
            "\n",
            "=================== Running with Adadelta Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 59s 46ms/step - loss: 2.4136 - accuracy: 0.1484 - val_loss: 2.0794 - val_accuracy: 0.2687\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 49s 45ms/step - loss: 2.0740 - accuracy: 0.2700 - val_loss: 1.8020 - val_accuracy: 0.4355\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 49s 45ms/step - loss: 1.8378 - accuracy: 0.3697 - val_loss: 1.6213 - val_accuracy: 0.5133\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 50s 46ms/step - loss: 1.6846 - accuracy: 0.4360 - val_loss: 1.4972 - val_accuracy: 0.5525\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 49s 44ms/step - loss: 1.5789 - accuracy: 0.4745 - val_loss: 1.4064 - val_accuracy: 0.5713\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 49s 45ms/step - loss: 1.5083 - accuracy: 0.4976 - val_loss: 1.3501 - val_accuracy: 0.5803\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 49s 45ms/step - loss: 1.4608 - accuracy: 0.5120 - val_loss: 1.3054 - val_accuracy: 0.5866\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 50s 46ms/step - loss: 1.4208 - accuracy: 0.5277 - val_loss: 1.2799 - val_accuracy: 0.5898\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 49s 45ms/step - loss: 1.3940 - accuracy: 0.5336 - val_loss: 1.2534 - val_accuracy: 0.5942\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 49s 44ms/step - loss: 1.3755 - accuracy: 0.5392 - val_loss: 1.2311 - val_accuracy: 0.5960\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.2374 - accuracy: 0.5933\n",
            "\n",
            " Model test accuracy with Adadelta optimizer is 59.33% \n",
            "\n",
            "\n",
            "=================== Running with RMSprop Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 76s 58ms/step - loss: 1.5089 - accuracy: 0.4864 - val_loss: 5.3370 - val_accuracy: 0.1065\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 1.2215 - accuracy: 0.5895 - val_loss: 4.4307 - val_accuracy: 0.0999\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 62s 56ms/step - loss: 1.0706 - accuracy: 0.6423 - val_loss: 2.5721 - val_accuracy: 0.1746\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 0.9649 - accuracy: 0.6790 - val_loss: 2.6001 - val_accuracy: 0.1082\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 61s 56ms/step - loss: 0.8760 - accuracy: 0.7114 - val_loss: 3.8590 - val_accuracy: 0.1055\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 0.8261 - accuracy: 0.7330 - val_loss: 4.4215 - val_accuracy: 0.1087\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 0.7723 - accuracy: 0.7464 - val_loss: 6.1971 - val_accuracy: 0.0983\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 0.7334 - accuracy: 0.7580 - val_loss: 3.5523 - val_accuracy: 0.1115\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 62s 57ms/step - loss: 0.6819 - accuracy: 0.7781 - val_loss: 4.3892 - val_accuracy: 0.1031\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 61s 56ms/step - loss: 0.6513 - accuracy: 0.7909 - val_loss: 8.5385 - val_accuracy: 0.1061\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 8.4594 - accuracy: 0.1033\n",
            "\n",
            " Model test accuracy with RMSprop optimizer is 10.33% \n",
            "\n",
            "\n",
            "=================== Running with Adam Optimizer ====================\n",
            "\n",
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 58s 45ms/step - loss: 0.6623 - accuracy: 0.7861 - val_loss: 2.4377 - val_accuracy: 0.1713\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.6992 - accuracy: 0.7745 - val_loss: 3.0610 - val_accuracy: 0.0909\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.7017 - accuracy: 0.7673 - val_loss: 6.2847 - val_accuracy: 0.1067\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.5965 - accuracy: 0.8017 - val_loss: 4.1945 - val_accuracy: 0.0992\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 49s 44ms/step - loss: 0.6006 - accuracy: 0.8033 - val_loss: 2.5628 - val_accuracy: 0.2694\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.7309 - accuracy: 0.7606 - val_loss: 2.8687 - val_accuracy: 0.1397\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.8597 - accuracy: 0.7137 - val_loss: 2.8306 - val_accuracy: 0.2124\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.6986 - accuracy: 0.7694 - val_loss: 6.4023 - val_accuracy: 0.0988\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 1.0351 - accuracy: 0.6527 - val_loss: 3.9293 - val_accuracy: 0.1011\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 1.2208 - accuracy: 0.5875 - val_loss: 3.0568 - val_accuracy: 0.0968\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 3.0392 - accuracy: 0.0986\n",
            "\n",
            " Model test accuracy with Adam optimizer is 9.86% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efnb0 = tf.keras.applications.efficientnet.EfficientNetB0(weights='imagenet',include_top=False,input_shape=(32,32,3), classes=10)\n",
        "\n",
        "modelef = Sequential()\n",
        "modelef.add(efnb0)\n",
        "modelef.add(GlobalAveragePooling2D())\n",
        "modelef.add(Dropout(0.5))\n",
        "modelef.add(Dense(10, activation='softmax'))\n",
        "\n",
        "modelef.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK7S-veHhgsy",
        "outputId": "6ee297cd-fa45-4369-c3df-ba5d173d2b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional)  (None, 1, 1, 1280)       4049571   \n",
            "                                                                 \n",
            " global_average_pooling2d_5   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 4,020,358\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelef.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=1e-4),metrics=['acc'])\n",
        "\n",
        "modelef.fit( x=X_train, y=y_train, batch_size=32, epochs=10, validation_split = 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxk-TwSRhUCJ",
        "outputId": "3b815570-ef94-48b8-a525-b0dadcbde2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 58s 45ms/step - loss: 0.6764 - acc: 0.7660 - val_loss: 1.9235 - val_acc: 0.4016\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.6200 - acc: 0.7821 - val_loss: 1.8210 - val_acc: 0.4236\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 48s 43ms/step - loss: 0.5743 - acc: 0.8007 - val_loss: 2.3080 - val_acc: 0.2895\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.5388 - acc: 0.8104 - val_loss: 2.5259 - val_acc: 0.2410\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.5016 - acc: 0.8246 - val_loss: 2.1873 - val_acc: 0.3233\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.4598 - acc: 0.8399 - val_loss: 2.0160 - val_acc: 0.4011\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.4390 - acc: 0.8457 - val_loss: 2.0936 - val_acc: 0.3868\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 48s 44ms/step - loss: 0.3971 - acc: 0.8633 - val_loss: 2.3728 - val_acc: 0.3366\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.3767 - acc: 0.8669 - val_loss: 2.9965 - val_acc: 0.2385\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 47s 43ms/step - loss: 0.3460 - acc: 0.8767 - val_loss: 2.6076 - val_acc: 0.3385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8418171810>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelef.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbtEOVYWjnk2",
        "outputId": "51d70def-795f-4f73-fc8a-646a647e770c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 2.6445 - acc: 0.3337\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6445159912109375, 0.3337000012397766]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw1f-5s8TGWB"
      },
      "outputs": [],
      "source": [
        "######################################################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}